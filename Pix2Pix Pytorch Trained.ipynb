{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c787059-3785-492b-b658-59b3ac7896ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from skimage.metrics import structural_similarity\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "import torchvision\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.models import vgg16, vgg19\n",
    "from torchmetrics.image.ssim import StructuralSimilarityIndexMeasure\n",
    "\n",
    "from utils.Create_Dataset import PairedImageDataset\n",
    "from utils.Pairing_Images import PairFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "197cfa49-3bdb-4c07-afd1-ccadca974530",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (256,256,3)\n",
    "TARGET_SHAPE = (256,256,3)\n",
    "BATCH_SIZE = 1\n",
    "base_dir = \"/home/nvlabs/.cache/kagglehub/datasets/requiemonk/sentinel12-image-pairs-segregated-by-terrain/versions/1/v_2\"\n",
    "# Dataset Hyper Parameters\n",
    "subset = \"agri\"\n",
    "save_dataframe = \"True\"\n",
    "s1_image_path = os.path.join(base_dir,subset + \"/s1\")\n",
    "s2_image_path = os.path.join(base_dir,subset + \"/s2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "457adf6e-ca46-4b08-9926-9246f0314c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Instances = 4000\n",
      "Sample Instances = 1000\n"
     ]
    }
   ],
   "source": [
    "image_dataset = PairedImageDataset(s1_dir=s1_image_path, s2_dir=s2_image_path, subset_name=subset, save_dataframe=save_dataframe)\n",
    "dataloader = DataLoader(image_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "print(f\"Total Instances = {len(image_dataset)}\")\n",
    "\n",
    "subset_indices = list(range(min(1000, len(image_dataset))))\n",
    "subset_dataset = Subset(image_dataset, subset_indices)\n",
    "subset_loader = DataLoader(subset_dataset, batch_size=1, shuffle=False)  # <--- Add this line\n",
    "\n",
    "print(f\"Sample Instances = {len(subset_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eba15a81-811f-4e2b-a20a-2610077404f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 256, 256]) torch.Size([3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "for i,j in subset_dataset:\n",
    "    print(i.shape,j.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0d100b-2c85-456c-8570-6ec88224fecc",
   "metadata": {},
   "source": [
    "# Model Instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b8d8d4-d511-4a7b-be7a-45377a3bef9d",
   "metadata": {},
   "source": [
    "Provide to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c204fe5-5598-403f-849f-148429d4d973",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "generator = UNetGenerator(in_channels=3, out_channels=2).to(device)\n",
    "discriminator = PatchDiscriminator(in_channels=3).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cace9dfd-72e8-4817-bd5b-fa0a9ed4d845",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe00b6f3-5bed-402f-b8ab-fecccb8ffcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(generated_image, target_image):\n",
    "    \"\"\"\n",
    "    Compute SSIM, PSNR, MSE, RMSE between generated and target images.\n",
    "    Both inputs are PyTorch tensors in the range [-1, 1].\n",
    "    \"\"\"\n",
    "    # Move to CPU, detach, and convert to numpy\n",
    "    generated_image = generated_image.squeeze().detach().cpu().numpy()\n",
    "    target_image = target_image.squeeze().detach().cpu().numpy()\n",
    "\n",
    "    # Rescale from [-1, 1] to [0, 1]\n",
    "    generated_image = (generated_image + 1) / 2.0\n",
    "    target_image = (target_image + 1) / 2.0\n",
    "\n",
    "    # Transpose from (C, H, W) to (H, W, C)\n",
    "    generated_image = np.transpose(generated_image, (1, 2, 0))\n",
    "    target_image = np.transpose(target_image, (1, 2, 0))\n",
    "\n",
    "    # Clip values\n",
    "    generated_image = np.clip(generated_image, 0, 1)\n",
    "    target_image = np.clip(target_image, 0, 1)\n",
    "\n",
    "    # Determine win_size\n",
    "    min_height = min(generated_image.shape[0], target_image.shape[0])\n",
    "    min_width = min(generated_image.shape[1], target_image.shape[1])\n",
    "    win_size = min(min_height, min_width)\n",
    "    win_size = win_size if win_size % 2 == 1 else win_size - 1  # make it odd\n",
    "\n",
    "    # Ensure win_size is at least 3\n",
    "    win_size = max(3, win_size)\n",
    "\n",
    "    # Compute metrics\n",
    "    ssim = structural_similarity(\n",
    "        target_image, generated_image,\n",
    "        channel_axis=-1, data_range=1.0,\n",
    "        win_size=win_size\n",
    "    )\n",
    "    psnr = peak_signal_noise_ratio(target_image, generated_image, data_range=1.0)\n",
    "    mse = mean_squared_error(target_image.flatten(), generated_image.flatten())\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    return {\n",
    "        \"SSIM\": ssim,\n",
    "        \"PSNR\": psnr,\n",
    "        \"MSE\": mse,\n",
    "        \"RMSE\": rmse\n",
    "    }\n",
    "\n",
    "def evaluate_model(test_loader, generator, device):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the test set using image quality metrics.\n",
    "    \"\"\"\n",
    "    ssim_scores, psnr_scores, mse_scores, rmse_scores = [], [], [], []\n",
    "\n",
    "    generator.to(device)\n",
    "    generator.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_image, target_image in test_loader:\n",
    "            input_image = input_image.to(device)\n",
    "            target_image = target_image.to(device)\n",
    "\n",
    "            # Ensure input is 4D (B, C, H, W)\n",
    "            if input_image.dim() == 3:\n",
    "                input_image = input_image.unsqueeze(0)\n",
    "                target_image = target_image.unsqueeze(0)\n",
    "\n",
    "            generated_image = generator(input_image)\n",
    "\n",
    "            metrics = compute_metrics(generated_image, target_image)\n",
    "            ssim_scores.append(metrics[\"SSIM\"])\n",
    "            psnr_scores.append(metrics[\"PSNR\"])\n",
    "            mse_scores.append(metrics[\"MSE\"])\n",
    "            rmse_scores.append(metrics[\"RMSE\"])\n",
    "\n",
    "    # Print averaged results\n",
    "    print(f\"SSIM: {np.mean(ssim_scores):.4f} | PSNR: {np.mean(psnr_scores):.2f} dB | MSE: {np.mean(mse_scores):.4f} | RMSE: {np.mean(rmse_scores):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b375ee6a-8512-4c08-81f0-227c5772abfe",
   "metadata": {},
   "source": [
    "# Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cbc26ac-eff7-43df-84d3-deb4863c6bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA_L1 = 100\n",
    "LAMBDA_PERC = 0.01\n",
    "loss_object = nn.BCEWithLogitsLoss()\n",
    "l1_loss_fn = nn.L1Loss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60a6488-2943-4232-9af7-4ccc3f212167",
   "metadata": {},
   "source": [
    "#### Perceptual loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "628939bc-e54f-40c4-9306-534d14e80bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nvlabs/miniconda3/envs/tf_gpu/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/nvlabs/miniconda3/envs/tf_gpu/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# ------------------> Build VGG Feature Extractor <------------------\n",
    "class VGG19FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG19FeatureExtractor, self).__init__()\n",
    "        vgg = models.vgg19(pretrained=True).features\n",
    "        self.feature_extractor = nn.Sequential(*list(vgg.children())[:12])  # Up to relu3_3\n",
    "        for param in self.feature_extractor.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.feature_extractor(x)\n",
    "\n",
    "# ------------------> Preprocess Function for VGG <------------------\n",
    "def preprocess(img_tensor):\n",
    "    \"\"\"\n",
    "    img_tensor: (B, 3, H, W), in [-1, 1]\n",
    "    Output: normalized for VGG (mean-subtracted and scaled)\n",
    "    \"\"\"\n",
    "    # Convert [-1, 1] to [0, 1]\n",
    "    img_tensor = (img_tensor + 1) / 2.0\n",
    "    normalize = T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225])\n",
    "    return normalize(img_tensor)\n",
    "\n",
    "# ------------------> Perceptual Loss Class <------------------\n",
    "class PerceptualLoss(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(PerceptualLoss, self).__init__()\n",
    "        self.vgg = VGG19FeatureExtractor().to(device)\n",
    "        self.l1 = nn.L1Loss()\n",
    "\n",
    "    def forward(self, y_true, y_pred):\n",
    "        # Preprocess and move to same device as VGG\n",
    "        y_true = preprocess(y_true).to(next(self.vgg.parameters()).device)\n",
    "        y_pred = preprocess(y_pred).to(next(self.vgg.parameters()).device)\n",
    "\n",
    "        # Extract VGG features\n",
    "        features_true = self.vgg(y_true)\n",
    "        features_pred = self.vgg(y_pred)\n",
    "\n",
    "        # Compute L1 loss between features\n",
    "        return self.l1(features_true, features_pred)\n",
    "\n",
    "# ------------------> Instantiate on the Correct Device <------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "perceptual_loss = PerceptualLoss(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a56dd97-a644-49c5-b23a-567821a98e75",
   "metadata": {},
   "source": [
    "#### Generator Loss = l1_loss * lambda_l1 + perceptaul_loss * lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9450d9a-a765-4f3d-b806-dcb5c5e6c297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(disc_generated_output, gen_output, target, include_perceptual):\n",
    "    real_labels = torch.ones_like(disc_generated_output)\n",
    "    gan_loss = loss_object(disc_generated_output, real_labels)\n",
    "    l1 = l1_loss_fn(gen_output, target)\n",
    "\n",
    "    if include_perceptual:\n",
    "        perc = perceptual_loss(target, gen_output)\n",
    "        total_loss = gan_loss + (LAMBDA_L1 * l1) + (LAMBDA_PERC * perc)\n",
    "        return total_loss, gan_loss, l1, perc\n",
    "    else:\n",
    "        total_loss = gan_loss + (LAMBDA_L1 * l1)\n",
    "        return total_loss, gan_loss, l1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ea006d-856e-4d89-8ca9-1eb45f5dc412",
   "metadata": {},
   "source": [
    "#### Discriminator Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "016771c7-15f0-41be-a5be-d272fcb7a563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "    real_labels = torch.ones_like(disc_real_output)\n",
    "    fake_labels = torch.zeros_like(disc_generated_output)\n",
    "\n",
    "    real_loss = loss_object(disc_real_output, real_labels)\n",
    "    fake_loss = loss_object(disc_generated_output, fake_labels)\n",
    "\n",
    "    total_disc_loss = real_loss + fake_loss\n",
    "    return total_disc_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31850f54-4eb6-4573-94b5-e4587cfdf49e",
   "metadata": {},
   "source": [
    "# Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8b9e2bd-b0c4-44a9-a20c-d2b7f8b91219",
   "metadata": {},
   "outputs": [],
   "source": [
    "GEN_LR = 0.0002\n",
    "DISC_LR = 0.0002\n",
    "BETA_1 = 0.5\n",
    "BETA_2 = 0.999\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60b05e70-3f89-4d8c-850f-8fb9a59a5fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = Adam(generator.parameters(), lr=GEN_LR, betas=(BETA_1, BETA_2))\n",
    "discriminator_optimizer = Adam(discriminator.parameters(), lr=DISC_LR, betas=(BETA_1, BETA_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e316bff6-8ebe-451d-8f81-5b3b622cd2c0",
   "metadata": {},
   "source": [
    "# Train Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb81f04b-1b10-4e6d-ba36-63b6511d1de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(grayscale, color, include_perceptual=False):\n",
    "    grayscale = grayscale.to(device)\n",
    "    color = color.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    fake_color = generator(grayscale)\n",
    "\n",
    "    disc_real_output = discriminator(grayscale, color)\n",
    "    disc_fake_output = discriminator(grayscale, fake_color.detach())\n",
    "\n",
    "    if include_perceptual:\n",
    "        gen_loss, adv_loss, l1_loss, perc_loss = generator_loss(disc_fake_output, fake_color, color, include_perceptual)\n",
    "    else:\n",
    "        gen_loss, adv_loss, l1_loss = generator_loss(disc_fake_output, fake_color, color, include_perceptual)\n",
    "\n",
    "    disc_loss = discriminator_loss(disc_real_output, disc_fake_output)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    generator_optimizer.zero_grad()\n",
    "    gen_loss.backward(retain_graph=True)\n",
    "    generator_optimizer.step()\n",
    "\n",
    "    discriminator_optimizer.zero_grad()\n",
    "    disc_loss.backward()\n",
    "    discriminator_optimizer.step()\n",
    "\n",
    "    if include_perceptual:\n",
    "        return gen_loss, adv_loss, l1_loss, perc_loss, disc_loss\n",
    "    else:\n",
    "        return gen_loss, adv_loss, l1_loss, disc_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5c3ff82-c01c-4915-a74c-5a8b0c30d66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = 'checkpoints_Pix2PixPerceptual'\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0dcf1f6-f9dd-4ecd-a681-cd739a3bfbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "loss_history = []\n",
    "include_metrics = True\n",
    "include_perceptual = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2e2a6b-d613-4a03-a050-b0991d4536b9",
   "metadata": {},
   "source": [
    "# Train Module "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d445acc-f28e-4457-8fd5-53fe7b4389fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 | Gen: 29.3811 | Adv: 9.9509 | L1: 0.1942 | Perc: 1.4057 | Disc: 0.0118 | Time: 0m 24s\n",
      "Epoch 2/100 | Gen: 29.4556 | Adv: 10.7915 | L1: 0.1865 | Perc: 1.4008 | Disc: 0.0006 | Time: 0m 24s\n",
      "Epoch 3/100 | Gen: 29.4244 | Adv: 11.3540 | L1: 0.1806 | Perc: 1.3965 | Disc: 0.0003 | Time: 0m 24s\n",
      "Epoch 4/100 | Gen: 27.9414 | Adv: 10.4167 | L1: 0.1751 | Perc: 1.3914 | Disc: 0.0585 | Time: 0m 25s\n",
      "Epoch 5/100 | Gen: 26.6102 | Adv: 9.6184 | L1: 0.1698 | Perc: 1.3866 | Disc: 0.0075 | Time: 0m 23s\n",
      "Epoch 6/100 | Gen: 27.0140 | Adv: 10.3690 | L1: 0.1663 | Perc: 1.3836 | Disc: 0.0012 | Time: 0m 23s\n",
      "Epoch 7/100 | Gen: 27.0042 | Adv: 10.8702 | L1: 0.1612 | Perc: 1.3786 | Disc: 0.0007 | Time: 0m 21s\n",
      "Epoch 8/100 | Gen: 25.9858 | Adv: 10.2474 | L1: 0.1572 | Perc: 1.3748 | Disc: 0.0268 | Time: 0m 26s\n",
      "Epoch 9/100 | Gen: 25.9290 | Adv: 10.5534 | L1: 0.1536 | Perc: 1.3709 | Disc: 0.0027 | Time: 0m 23s\n",
      "Epoch 10/100 | Gen: 26.2037 | Adv: 11.1695 | L1: 0.1502 | Perc: 1.3673 | Disc: 0.0011 | Time: 0m 25s\n",
      "-------------------------------------\n",
      "SSIM: 0.8018 | PSNR: 19.55 dB | MSE: 0.0120 | RMSE: 0.1074\n",
      "-------------------------------------\n",
      "Epoch 11/100 | Gen: 25.9236 | Adv: 11.2150 | L1: 0.1469 | Perc: 1.3642 | Disc: 0.0337 | Time: 0m 23s\n",
      "Epoch 12/100 | Gen: 24.7858 | Adv: 10.3207 | L1: 0.1445 | Perc: 1.3609 | Disc: 0.0027 | Time: 0m 25s\n",
      "Epoch 13/100 | Gen: 25.2127 | Adv: 11.0835 | L1: 0.1412 | Perc: 1.3574 | Disc: 0.0012 | Time: 0m 23s\n",
      "Epoch 14/100 | Gen: 25.3344 | Adv: 11.4582 | L1: 0.1386 | Perc: 1.3556 | Disc: 0.0007 | Time: 0m 22s\n",
      "Epoch 15/100 | Gen: 25.5042 | Adv: 11.9287 | L1: 0.1356 | Perc: 1.3509 | Disc: 0.0012 | Time: 0m 22s\n",
      "Epoch 16/100 | Gen: 25.9069 | Adv: 12.6054 | L1: 0.1329 | Perc: 1.3477 | Disc: 0.0001 | Time: 0m 22s\n",
      "Epoch 17/100 | Gen: 26.0996 | Adv: 12.9550 | L1: 0.1313 | Perc: 1.3450 | Disc: 0.0001 | Time: 0m 22s\n",
      "Epoch 18/100 | Gen: 26.3630 | Adv: 13.4557 | L1: 0.1289 | Perc: 1.3405 | Disc: 0.0001 | Time: 0m 23s\n",
      "Epoch 19/100 | Gen: 25.6168 | Adv: 13.0038 | L1: 0.1260 | Perc: 1.3368 | Disc: 0.0499 | Time: 0m 20s\n",
      "Epoch 20/100 | Gen: 23.0092 | Adv: 10.4398 | L1: 0.1256 | Perc: 1.3334 | Disc: 0.0027 | Time: 0m 25s\n",
      "-------------------------------------\n",
      "SSIM: 0.8627 | PSNR: 21.23 dB | MSE: 0.0082 | RMSE: 0.0886\n",
      "-------------------------------------\n",
      "Epoch 21/100 | Gen: 23.5805 | Adv: 11.2338 | L1: 0.1233 | Perc: 1.3301 | Disc: 0.0007 | Time: 0m 23s\n",
      "Epoch 22/100 | Gen: 24.0217 | Adv: 11.8588 | L1: 0.1215 | Perc: 1.3264 | Disc: 0.0004 | Time: 0m 23s\n",
      "Epoch 23/100 | Gen: 24.3149 | Adv: 12.3467 | L1: 0.1195 | Perc: 1.3227 | Disc: 0.0016 | Time: 0m 22s\n",
      "Epoch 24/100 | Gen: 23.8218 | Adv: 12.0397 | L1: 0.1177 | Perc: 1.3191 | Disc: 0.0323 | Time: 0m 24s\n",
      "Epoch 25/100 | Gen: 23.8484 | Adv: 12.0933 | L1: 0.1174 | Perc: 1.3160 | Disc: 0.0011 | Time: 0m 22s\n",
      "Epoch 26/100 | Gen: 24.1527 | Adv: 12.5256 | L1: 0.1161 | Perc: 1.3127 | Disc: 0.0005 | Time: 0m 21s\n",
      "Epoch 27/100 | Gen: 24.3915 | Adv: 12.9724 | L1: 0.1141 | Perc: 1.3088 | Disc: 0.0004 | Time: 0m 26s\n",
      "Epoch 28/100 | Gen: 24.6688 | Adv: 13.4079 | L1: 0.1125 | Perc: 1.3053 | Disc: 0.0002 | Time: 0m 24s\n",
      "Epoch 29/100 | Gen: 24.8590 | Adv: 13.6806 | L1: 0.1117 | Perc: 1.3022 | Disc: 0.0001 | Time: 0m 24s\n",
      "Epoch 30/100 | Gen: 25.1979 | Adv: 14.2147 | L1: 0.1097 | Perc: 1.2981 | Disc: 0.0001 | Time: 0m 20s\n",
      "-------------------------------------\n",
      "SSIM: 0.8880 | PSNR: 22.06 dB | MSE: 0.0068 | RMSE: 0.0807\n",
      "-------------------------------------\n",
      "Epoch 31/100 | Gen: 23.6835 | Adv: 12.7590 | L1: 0.1091 | Perc: 1.2952 | Disc: 0.0431 | Time: 0m 27s\n",
      "Epoch 32/100 | Gen: 23.8949 | Adv: 13.0509 | L1: 0.1083 | Perc: 1.2930 | Disc: 0.0009 | Time: 0m 22s\n",
      "Epoch 33/100 | Gen: 23.8464 | Adv: 13.0873 | L1: 0.1075 | Perc: 1.2883 | Disc: 0.0003 | Time: 0m 23s\n",
      "Epoch 34/100 | Gen: 24.1500 | Adv: 13.5208 | L1: 0.1062 | Perc: 1.2854 | Disc: 0.0004 | Time: 0m 23s\n",
      "Epoch 35/100 | Gen: 24.3053 | Adv: 13.8471 | L1: 0.1045 | Perc: 1.2818 | Disc: 0.0002 | Time: 0m 22s\n",
      "Epoch 36/100 | Gen: 23.9640 | Adv: 13.5429 | L1: 0.1041 | Perc: 1.2789 | Disc: 0.0323 | Time: 0m 23s\n",
      "Epoch 37/100 | Gen: 24.0074 | Adv: 13.6476 | L1: 0.1035 | Perc: 1.2757 | Disc: 0.0005 | Time: 0m 23s\n",
      "Epoch 38/100 | Gen: 24.0837 | Adv: 13.7973 | L1: 0.1027 | Perc: 1.2726 | Disc: 0.0003 | Time: 0m 27s\n",
      "Epoch 39/100 | Gen: 24.0677 | Adv: 13.9364 | L1: 0.1012 | Perc: 1.2689 | Disc: 0.0002 | Time: 0m 24s\n",
      "Epoch 40/100 | Gen: 24.0879 | Adv: 14.0234 | L1: 0.1005 | Perc: 1.2660 | Disc: 0.0001 | Time: 0m 22s\n",
      "-------------------------------------\n",
      "SSIM: 0.9033 | PSNR: 22.74 dB | MSE: 0.0058 | RMSE: 0.0746\n",
      "-------------------------------------\n",
      "Epoch 41/100 | Gen: 24.3781 | Adv: 14.3591 | L1: 0.1001 | Perc: 1.2636 | Disc: 0.0001 | Time: 0m 24s\n",
      "Epoch 42/100 | Gen: 24.6304 | Adv: 14.7070 | L1: 0.0991 | Perc: 1.2596 | Disc: 0.0001 | Time: 0m 22s\n",
      "Epoch 43/100 | Gen: 23.1085 | Adv: 13.2959 | L1: 0.0980 | Perc: 1.2567 | Disc: 0.0278 | Time: 0m 22s\n",
      "Epoch 44/100 | Gen: 22.9596 | Adv: 13.2440 | L1: 0.0970 | Perc: 1.2532 | Disc: 0.0076 | Time: 0m 21s\n",
      "Epoch 45/100 | Gen: 23.4268 | Adv: 13.7548 | L1: 0.0966 | Perc: 1.2502 | Disc: 0.0005 | Time: 0m 22s\n",
      "Epoch 46/100 | Gen: 23.5459 | Adv: 13.9155 | L1: 0.0962 | Perc: 1.2476 | Disc: 0.0002 | Time: 0m 25s\n",
      "Epoch 47/100 | Gen: 23.8746 | Adv: 14.3426 | L1: 0.0952 | Perc: 1.2442 | Disc: 0.0002 | Time: 0m 26s\n",
      "Epoch 48/100 | Gen: 24.0264 | Adv: 14.6219 | L1: 0.0939 | Perc: 1.2402 | Disc: 0.0001 | Time: 0m 24s\n",
      "Epoch 49/100 | Gen: 24.4414 | Adv: 15.0234 | L1: 0.0941 | Perc: 1.2385 | Disc: 0.0001 | Time: 0m 23s\n",
      "Epoch 50/100 | Gen: 22.5936 | Adv: 13.2739 | L1: 0.0931 | Perc: 1.2348 | Disc: 0.0287 | Time: 0m 23s\n",
      "-------------------------------------\n",
      "SSIM: 0.9173 | PSNR: 23.41 dB | MSE: 0.0050 | RMSE: 0.0692\n",
      "-------------------------------------\n",
      "Epoch 51/100 | Gen: 22.8075 | Adv: 13.5507 | L1: 0.0924 | Perc: 1.2317 | Disc: 0.0009 | Time: 0m 24s\n",
      "Epoch 52/100 | Gen: 23.2189 | Adv: 13.9911 | L1: 0.0922 | Perc: 1.2293 | Disc: 0.0003 | Time: 0m 23s\n",
      "Epoch 53/100 | Gen: 23.5154 | Adv: 14.2892 | L1: 0.0921 | Perc: 1.2271 | Disc: 0.0002 | Time: 0m 27s\n",
      "Epoch 54/100 | Gen: 23.6169 | Adv: 14.5003 | L1: 0.0910 | Perc: 1.2234 | Disc: 0.0001 | Time: 0m 23s\n",
      "Epoch 55/100 | Gen: 23.9213 | Adv: 14.9233 | L1: 0.0899 | Perc: 1.2196 | Disc: 0.0008 | Time: 0m 25s\n",
      "Epoch 56/100 | Gen: 24.9551 | Adv: 15.9931 | L1: 0.0895 | Perc: 1.2174 | Disc: 0.0001 | Time: 0m 26s\n",
      "Epoch 57/100 | Gen: 25.2206 | Adv: 16.3009 | L1: 0.0891 | Perc: 1.2147 | Disc: 0.0000 | Time: 0m 19s\n",
      "Epoch 58/100 | Gen: 23.9987 | Adv: 15.1084 | L1: 0.0888 | Perc: 1.2119 | Disc: 0.0459 | Time: 0m 23s\n",
      "Epoch 59/100 | Gen: 22.3023 | Adv: 13.4466 | L1: 0.0884 | Perc: 1.2095 | Disc: 0.0201 | Time: 0m 26s\n",
      "Epoch 60/100 | Gen: 22.8840 | Adv: 14.0901 | L1: 0.0878 | Perc: 1.2065 | Disc: 0.0005 | Time: 0m 22s\n",
      "-------------------------------------\n",
      "SSIM: 0.9238 | PSNR: 23.77 dB | MSE: 0.0046 | RMSE: 0.0664\n",
      "-------------------------------------\n",
      "Epoch 61/100 | Gen: 22.8985 | Adv: 14.2330 | L1: 0.0865 | Perc: 1.2028 | Disc: 0.0003 | Time: 0m 21s\n",
      "Epoch 62/100 | Gen: 23.4576 | Adv: 14.7742 | L1: 0.0867 | Perc: 1.2010 | Disc: 0.0002 | Time: 0m 23s\n",
      "Epoch 63/100 | Gen: 23.8374 | Adv: 15.1699 | L1: 0.0866 | Perc: 1.1986 | Disc: 0.0002 | Time: 0m 23s\n",
      "Epoch 64/100 | Gen: 24.1422 | Adv: 15.5595 | L1: 0.0857 | Perc: 1.1954 | Disc: 0.0001 | Time: 0m 23s\n",
      "Epoch 65/100 | Gen: 22.9702 | Adv: 14.4807 | L1: 0.0848 | Perc: 1.1922 | Disc: 0.0223 | Time: 0m 23s\n",
      "Epoch 66/100 | Gen: 22.8952 | Adv: 14.4003 | L1: 0.0848 | Perc: 1.1899 | Disc: 0.0133 | Time: 0m 23s\n",
      "Epoch 67/100 | Gen: 22.4448 | Adv: 13.9849 | L1: 0.0845 | Perc: 1.1879 | Disc: 0.0034 | Time: 0m 22s\n",
      "Epoch 68/100 | Gen: 23.0000 | Adv: 14.6259 | L1: 0.0836 | Perc: 1.1846 | Disc: 0.0002 | Time: 0m 23s\n",
      "Epoch 69/100 | Gen: 23.4267 | Adv: 15.0903 | L1: 0.0832 | Perc: 1.1819 | Disc: 0.0002 | Time: 0m 21s\n",
      "Epoch 70/100 | Gen: 23.8451 | Adv: 15.5351 | L1: 0.0830 | Perc: 1.1795 | Disc: 0.0001 | Time: 0m 23s\n",
      "-------------------------------------\n",
      "SSIM: 0.9325 | PSNR: 24.35 dB | MSE: 0.0041 | RMSE: 0.0622\n",
      "-------------------------------------\n",
      "Epoch 71/100 | Gen: 24.2446 | Adv: 15.9386 | L1: 0.0829 | Perc: 1.1778 | Disc: 0.0001 | Time: 0m 28s\n",
      "Epoch 72/100 | Gen: 24.6224 | Adv: 16.3870 | L1: 0.0822 | Perc: 1.1745 | Disc: 0.0001 | Time: 0m 26s\n",
      "Epoch 73/100 | Gen: 20.8409 | Adv: 12.6803 | L1: 0.0815 | Perc: 1.1716 | Disc: 0.0351 | Time: 0m 27s\n",
      "Epoch 74/100 | Gen: 21.9704 | Adv: 13.8535 | L1: 0.0811 | Perc: 1.1693 | Disc: 0.0005 | Time: 0m 25s\n",
      "Epoch 75/100 | Gen: 22.4685 | Adv: 14.3776 | L1: 0.0808 | Perc: 1.1665 | Disc: 0.0002 | Time: 0m 23s\n",
      "Epoch 76/100 | Gen: 22.6138 | Adv: 14.5152 | L1: 0.0809 | Perc: 1.1650 | Disc: 0.0244 | Time: 0m 23s\n",
      "Epoch 77/100 | Gen: 22.6672 | Adv: 14.6192 | L1: 0.0804 | Perc: 1.1621 | Disc: 0.0185 | Time: 0m 24s\n",
      "Epoch 78/100 | Gen: 23.1513 | Adv: 15.1552 | L1: 0.0798 | Perc: 1.1599 | Disc: 0.0006 | Time: 0m 27s\n",
      "Epoch 79/100 | Gen: 23.1884 | Adv: 15.2300 | L1: 0.0795 | Perc: 1.1575 | Disc: 0.0003 | Time: 0m 23s\n",
      "Epoch 80/100 | Gen: 23.2999 | Adv: 15.3326 | L1: 0.0796 | Perc: 1.1561 | Disc: 0.0002 | Time: 0m 23s\n",
      "-------------------------------------\n",
      "SSIM: 0.9399 | PSNR: 24.79 dB | MSE: 0.0037 | RMSE: 0.0591\n",
      "-------------------------------------\n",
      "Epoch 81/100 | Gen: 23.6612 | Adv: 15.7354 | L1: 0.0791 | Perc: 1.1536 | Disc: 0.0002 | Time: 0m 26s\n",
      "Epoch 82/100 | Gen: 23.9273 | Adv: 16.0779 | L1: 0.0784 | Perc: 1.1507 | Disc: 0.0002 | Time: 0m 22s\n",
      "Epoch 83/100 | Gen: 24.2357 | Adv: 16.4399 | L1: 0.0778 | Perc: 1.1479 | Disc: 0.0001 | Time: 0m 23s\n",
      "Epoch 84/100 | Gen: 21.6042 | Adv: 13.8235 | L1: 0.0777 | Perc: 1.1463 | Disc: 0.0339 | Time: 0m 23s\n",
      "Epoch 85/100 | Gen: 22.3679 | Adv: 14.5607 | L1: 0.0780 | Perc: 1.1453 | Disc: 0.0006 | Time: 0m 28s\n",
      "Epoch 86/100 | Gen: 22.9755 | Adv: 15.1912 | L1: 0.0777 | Perc: 1.1428 | Disc: 0.0004 | Time: 0m 21s\n",
      "Epoch 87/100 | Gen: 22.9147 | Adv: 15.2075 | L1: 0.0770 | Perc: 1.1401 | Disc: 0.0003 | Time: 0m 20s\n",
      "Epoch 88/100 | Gen: 22.5677 | Adv: 14.9007 | L1: 0.0766 | Perc: 1.1380 | Disc: 0.0593 | Time: 0m 22s\n",
      "Epoch 89/100 | Gen: 21.0486 | Adv: 13.4073 | L1: 0.0763 | Perc: 1.1359 | Disc: 0.0021 | Time: 0m 24s\n",
      "Epoch 90/100 | Gen: 21.5952 | Adv: 13.9736 | L1: 0.0761 | Perc: 1.1343 | Disc: 0.0008 | Time: 0m 23s\n",
      "-------------------------------------\n",
      "SSIM: 0.9405 | PSNR: 24.83 dB | MSE: 0.0037 | RMSE: 0.0589\n",
      "-------------------------------------\n",
      "Epoch 91/100 | Gen: 21.8006 | Adv: 14.1902 | L1: 0.0760 | Perc: 1.1323 | Disc: 0.0004 | Time: 0m 20s\n",
      "Epoch 92/100 | Gen: 22.1264 | Adv: 14.5786 | L1: 0.0754 | Perc: 1.1298 | Disc: 0.0003 | Time: 0m 22s\n",
      "Epoch 93/100 | Gen: 22.6835 | Adv: 15.1676 | L1: 0.0750 | Perc: 1.1280 | Disc: 0.0002 | Time: 0m 22s\n",
      "Epoch 94/100 | Gen: 22.4225 | Adv: 14.9370 | L1: 0.0747 | Perc: 1.1261 | Disc: 0.0197 | Time: 0m 21s\n",
      "Epoch 95/100 | Gen: 22.2632 | Adv: 14.7356 | L1: 0.0752 | Perc: 1.1247 | Disc: 0.0014 | Time: 0m 25s\n",
      "Epoch 96/100 | Gen: 22.7945 | Adv: 15.3310 | L1: 0.0745 | Perc: 1.1222 | Disc: 0.0004 | Time: 0m 24s\n",
      "Epoch 97/100 | Gen: 22.9815 | Adv: 15.5581 | L1: 0.0741 | Perc: 1.1205 | Disc: 0.0002 | Time: 0m 24s\n",
      "Epoch 98/100 | Gen: 23.3669 | Adv: 15.9588 | L1: 0.0740 | Perc: 1.1186 | Disc: 0.0002 | Time: 0m 23s\n",
      "Epoch 99/100 | Gen: 23.6836 | Adv: 16.3407 | L1: 0.0733 | Perc: 1.1160 | Disc: 0.0001 | Time: 0m 23s\n",
      "Epoch 100/100 | Gen: 24.1977 | Adv: 16.8412 | L1: 0.0735 | Perc: 1.1148 | Disc: 0.0001 | Time: 0m 25s\n",
      "-------------------------------------\n",
      "SSIM: 0.9472 | PSNR: 25.43 dB | MSE: 0.0032 | RMSE: 0.0551\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "loss_history = []\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Accumulators\n",
    "    gen_loss_total = adv_loss_total = l1_loss_total = perc_loss_total = disc_loss_total = 0\n",
    "    num_batches = len(subset_loader)\n",
    "\n",
    "    for grayscale, color in subset_loader:\n",
    "        grayscale, color = grayscale.to(device), color.to(device)\n",
    "\n",
    "        if include_perceptual:\n",
    "            gen_loss, adv_loss, l1_loss, perc_loss, disc_loss = train_step(grayscale, color, include_perceptual)\n",
    "            perc_loss_total += perc_loss.item()\n",
    "        else:\n",
    "            gen_loss, adv_loss, l1_loss, disc_loss = train_step(grayscale, color, include_perceptual)\n",
    "            perc_loss = torch.tensor(0.0)  # Placeholder if not used\n",
    "\n",
    "        # Accumulate all losses\n",
    "        gen_loss_total += gen_loss.item()\n",
    "        adv_loss_total += adv_loss.item()\n",
    "        l1_loss_total += l1_loss.item()\n",
    "        disc_loss_total += disc_loss.item()\n",
    "\n",
    "    # Epoch time\n",
    "    elapsed_time = time.time() - start_time\n",
    "    minutes, seconds = divmod(elapsed_time, 60)\n",
    "\n",
    "    # Store loss values (averaged per batch)\n",
    "    loss_history.append([\n",
    "        gen_loss_total / num_batches,\n",
    "        adv_loss_total / num_batches,\n",
    "        l1_loss_total / num_batches,\n",
    "        perc_loss_total / num_batches if include_perceptual else 0.0,\n",
    "        disc_loss_total / num_batches\n",
    "    ])\n",
    "\n",
    "    # Print loss summary\n",
    "    if include_perceptual:\n",
    "        print(f\"Epoch {epoch}/{EPOCHS} | Gen: {gen_loss_total / num_batches:.4f} | \"\n",
    "              f\"Adv: {adv_loss_total / num_batches:.4f} | L1: {l1_loss_total / num_batches:.4f} | \"\n",
    "              f\"Perc: {perc_loss_total / num_batches:.4f} | Disc: {disc_loss_total / num_batches:.4f} \"\n",
    "              f\"| Time: {int(minutes)}m {int(seconds)}s\")\n",
    "    else:\n",
    "        print(f\"Epoch {epoch}/{EPOCHS} | Gen: {gen_loss_total / num_batches:.4f} | \"\n",
    "              f\"Adv: {adv_loss_total / num_batches:.4f} | L1: {l1_loss_total / num_batches:.4f} | \"\n",
    "              f\"Disc: {disc_loss_total / num_batches:.4f} | Time: {int(minutes)}m {int(seconds)}s\")\n",
    "\n",
    "    # Evaluate model every 10 epochs\n",
    "    if epoch % 10 == 0 and include_metrics:\n",
    "        print(\"-------------------------------------\")\n",
    "        evaluate_model(subset_loader, generator, device)\n",
    "        print(\"-------------------------------------\")\n",
    "\n",
    "        # Save models\n",
    "        torch.save(generator.state_dict(), f\"Models/generator_epoch_{epoch}.pth\")\n",
    "        torch.save(discriminator.state_dict(), f\"Models/discriminator_epoch_{epoch}.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3889b5f-0068-4884-8b97-773d5b65825b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/100 | Gen: 23.5989 | Adv: 16.2576 | L1: 0.0733 | Perc: 1.1129 | Disc: 0.0211 | Time: 0m 25s\n",
      "Epoch 102/100 | Gen: 22.0563 | Adv: 14.7718 | L1: 0.0727 | Perc: 1.1106 | Disc: 0.0070 | Time: 0m 25s\n",
      "Epoch 103/100 | Gen: 22.1233 | Adv: 14.8447 | L1: 0.0727 | Perc: 1.1094 | Disc: 0.0005 | Time: 0m 23s\n",
      "Epoch 104/100 | Gen: 22.4289 | Adv: 15.1738 | L1: 0.0724 | Perc: 1.1075 | Disc: 0.0010 | Time: 0m 26s\n",
      "Epoch 105/100 | Gen: 23.0538 | Adv: 15.8274 | L1: 0.0722 | Perc: 1.1057 | Disc: 0.0003 | Time: 0m 22s\n",
      "Epoch 106/100 | Gen: 23.6436 | Adv: 16.4542 | L1: 0.0718 | Perc: 1.1038 | Disc: 0.0001 | Time: 0m 21s\n",
      "Epoch 107/100 | Gen: 23.8929 | Adv: 16.6963 | L1: 0.0719 | Perc: 1.1022 | Disc: 0.0001 | Time: 0m 22s\n",
      "Epoch 108/100 | Gen: 24.2676 | Adv: 17.0931 | L1: 0.0716 | Perc: 1.1007 | Disc: 0.0000 | Time: 0m 23s\n",
      "Epoch 109/100 | Gen: 24.5428 | Adv: 17.4048 | L1: 0.0713 | Perc: 1.0988 | Disc: 0.0000 | Time: 0m 22s\n",
      "Epoch 110/100 | Gen: 23.7970 | Adv: 16.6597 | L1: 0.0713 | Perc: 1.0977 | Disc: 0.0396 | Time: 0m 22s\n",
      "-------------------------------------\n",
      "SSIM: 0.9507 | PSNR: 25.75 dB | MSE: 0.0030 | RMSE: 0.0531\n",
      "-------------------------------------\n",
      "Epoch 111/100 | Gen: 22.0876 | Adv: 15.0022 | L1: 0.0707 | Perc: 1.0952 | Disc: 0.0030 | Time: 0m 25s\n",
      "Epoch 112/100 | Gen: 22.3019 | Adv: 15.2413 | L1: 0.0705 | Perc: 1.0935 | Disc: 0.0003 | Time: 0m 23s\n",
      "Epoch 113/100 | Gen: 22.6208 | Adv: 15.5429 | L1: 0.0707 | Perc: 1.0927 | Disc: 0.0002 | Time: 0m 23s\n",
      "Epoch 114/100 | Gen: 23.0877 | Adv: 16.0513 | L1: 0.0703 | Perc: 1.0907 | Disc: 0.0002 | Time: 0m 24s\n",
      "Epoch 115/100 | Gen: 23.2524 | Adv: 16.2719 | L1: 0.0697 | Perc: 1.0883 | Disc: 0.0001 | Time: 0m 22s\n",
      "Epoch 116/100 | Gen: 22.0139 | Adv: 15.0232 | L1: 0.0698 | Perc: 1.0874 | Disc: 0.0598 | Time: 0m 22s\n",
      "Epoch 117/100 | Gen: 21.6963 | Adv: 14.7206 | L1: 0.0696 | Perc: 1.0858 | Disc: 0.0067 | Time: 0m 22s\n",
      "Epoch 118/100 | Gen: 21.9303 | Adv: 14.9672 | L1: 0.0695 | Perc: 1.0847 | Disc: 0.0017 | Time: 0m 23s\n",
      "Epoch 119/100 | Gen: 21.9698 | Adv: 15.0208 | L1: 0.0694 | Perc: 1.0830 | Disc: 0.0002 | Time: 0m 24s\n",
      "Epoch 120/100 | Gen: 22.3455 | Adv: 15.4321 | L1: 0.0690 | Perc: 1.0812 | Disc: 0.0002 | Time: 0m 22s\n",
      "-------------------------------------\n",
      "SSIM: 0.9530 | PSNR: 25.93 dB | MSE: 0.0029 | RMSE: 0.0521\n",
      "-------------------------------------\n",
      "Epoch 121/100 | Gen: 22.6015 | Adv: 15.7057 | L1: 0.0688 | Perc: 1.0796 | Disc: 0.0001 | Time: 0m 22s\n",
      "Epoch 122/100 | Gen: 22.9786 | Adv: 16.0933 | L1: 0.0687 | Perc: 1.0784 | Disc: 0.0001 | Time: 0m 24s\n",
      "Epoch 123/100 | Gen: 23.2501 | Adv: 16.3763 | L1: 0.0686 | Perc: 1.0770 | Disc: 0.0001 | Time: 0m 25s\n",
      "Epoch 124/100 | Gen: 23.8065 | Adv: 16.9257 | L1: 0.0687 | Perc: 1.0761 | Disc: 0.0001 | Time: 0m 23s\n",
      "Epoch 125/100 | Gen: 21.9318 | Adv: 15.1134 | L1: 0.0681 | Perc: 1.0734 | Disc: 0.0161 | Time: 0m 22s\n",
      "Epoch 126/100 | Gen: 22.4490 | Adv: 15.6569 | L1: 0.0678 | Perc: 1.0718 | Disc: 0.0215 | Time: 0m 22s\n",
      "Epoch 127/100 | Gen: 21.5568 | Adv: 14.7235 | L1: 0.0682 | Perc: 1.0715 | Disc: 0.0029 | Time: 0m 22s\n",
      "Epoch 128/100 | Gen: 22.2183 | Adv: 15.4558 | L1: 0.0675 | Perc: 1.0690 | Disc: 0.0002 | Time: 0m 22s\n",
      "Epoch 129/100 | Gen: 22.6763 | Adv: 15.9361 | L1: 0.0673 | Perc: 1.0673 | Disc: 0.0001 | Time: 0m 23s\n",
      "Epoch 130/100 | Gen: 23.0618 | Adv: 16.3040 | L1: 0.0675 | Perc: 1.0669 | Disc: 0.0001 | Time: 0m 24s\n",
      "-------------------------------------\n",
      "SSIM: 0.9547 | PSNR: 26.07 dB | MSE: 0.0028 | RMSE: 0.0512\n",
      "-------------------------------------\n",
      "Epoch 131/100 | Gen: 23.3924 | Adv: 16.6446 | L1: 0.0674 | Perc: 1.0658 | Disc: 0.0001 | Time: 0m 22s\n",
      "Epoch 132/100 | Gen: 23.6329 | Adv: 16.9396 | L1: 0.0668 | Perc: 1.0633 | Disc: 0.0001 | Time: 0m 23s\n",
      "Epoch 133/100 | Gen: 23.6564 | Adv: 16.9696 | L1: 0.0668 | Perc: 1.0623 | Disc: 0.0465 | Time: 0m 23s\n",
      "Epoch 134/100 | Gen: 22.1515 | Adv: 15.4558 | L1: 0.0669 | Perc: 1.0615 | Disc: 0.0065 | Time: 0m 23s\n",
      "Epoch 135/100 | Gen: 23.0011 | Adv: 16.3233 | L1: 0.0667 | Perc: 1.0601 | Disc: 0.0007 | Time: 0m 24s\n",
      "Epoch 136/100 | Gen: 23.0196 | Adv: 16.3860 | L1: 0.0662 | Perc: 1.0582 | Disc: 0.0004 | Time: 0m 25s\n",
      "Epoch 137/100 | Gen: 22.8031 | Adv: 16.2039 | L1: 0.0659 | Perc: 1.0564 | Disc: 0.0001 | Time: 0m 25s\n",
      "Epoch 138/100 | Gen: 23.3174 | Adv: 16.7075 | L1: 0.0660 | Perc: 1.0556 | Disc: 0.0001 | Time: 0m 25s\n",
      "Epoch 139/100 | Gen: 23.7511 | Adv: 17.1145 | L1: 0.0663 | Perc: 1.0553 | Disc: 0.0001 | Time: 0m 21s\n",
      "Epoch 140/100 | Gen: 23.8091 | Adv: 17.2053 | L1: 0.0659 | Perc: 1.0533 | Disc: 0.0000 | Time: 0m 24s\n",
      "-------------------------------------\n",
      "SSIM: 0.9569 | PSNR: 26.34 dB | MSE: 0.0026 | RMSE: 0.0496\n",
      "-------------------------------------\n",
      "Epoch 141/100 | Gen: 23.9961 | Adv: 17.4343 | L1: 0.0655 | Perc: 1.0511 | Disc: 0.0000 | Time: 0m 22s\n",
      "Epoch 142/100 | Gen: 24.5188 | Adv: 17.9598 | L1: 0.0655 | Perc: 1.0503 | Disc: 0.0000 | Time: 0m 23s\n",
      "Epoch 143/100 | Gen: 24.4663 | Adv: 17.9308 | L1: 0.0653 | Perc: 1.0488 | Disc: 0.0299 | Time: 0m 23s\n",
      "Epoch 144/100 | Gen: 22.8510 | Adv: 16.3393 | L1: 0.0650 | Perc: 1.0472 | Disc: 0.0029 | Time: 0m 24s\n",
      "Epoch 145/100 | Gen: 23.3700 | Adv: 16.8545 | L1: 0.0651 | Perc: 1.0465 | Disc: 0.0002 | Time: 0m 23s\n",
      "Epoch 146/100 | Gen: 23.5211 | Adv: 17.0246 | L1: 0.0649 | Perc: 1.0452 | Disc: 0.0001 | Time: 0m 25s\n",
      "Epoch 147/100 | Gen: 23.6694 | Adv: 17.2088 | L1: 0.0645 | Perc: 1.0434 | Disc: 0.0001 | Time: 0m 24s\n",
      "Epoch 148/100 | Gen: 23.8991 | Adv: 17.4162 | L1: 0.0647 | Perc: 1.0428 | Disc: 0.0001 | Time: 0m 22s\n",
      "Epoch 149/100 | Gen: 24.3241 | Adv: 17.8478 | L1: 0.0647 | Perc: 1.0419 | Disc: 0.0000 | Time: 0m 23s\n",
      "Epoch 150/100 | Gen: 24.5868 | Adv: 18.1279 | L1: 0.0645 | Perc: 1.0404 | Disc: 0.0000 | Time: 0m 20s\n",
      "-------------------------------------\n",
      "SSIM: 0.9591 | PSNR: 26.57 dB | MSE: 0.0025 | RMSE: 0.0484\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(101, 151):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Accumulators\n",
    "    gen_loss_total = adv_loss_total = l1_loss_total = perc_loss_total = disc_loss_total = 0\n",
    "    num_batches = len(subset_loader)\n",
    "\n",
    "    for grayscale, color in subset_loader:\n",
    "        grayscale, color = grayscale.to(device), color.to(device)\n",
    "\n",
    "        if include_perceptual:\n",
    "            gen_loss, adv_loss, l1_loss, perc_loss, disc_loss = train_step(grayscale, color, include_perceptual)\n",
    "            perc_loss_total += perc_loss.item()\n",
    "        else:\n",
    "            gen_loss, adv_loss, l1_loss, disc_loss = train_step(grayscale, color, include_perceptual)\n",
    "            perc_loss = torch.tensor(0.0)  # Placeholder if not used\n",
    "\n",
    "        # Accumulate all losses\n",
    "        gen_loss_total += gen_loss.item()\n",
    "        adv_loss_total += adv_loss.item()\n",
    "        l1_loss_total += l1_loss.item()\n",
    "        disc_loss_total += disc_loss.item()\n",
    "\n",
    "    # Epoch time\n",
    "    elapsed_time = time.time() - start_time\n",
    "    minutes, seconds = divmod(elapsed_time, 60)\n",
    "\n",
    "    # Store loss values (averaged per batch)\n",
    "    loss_history.append([\n",
    "        gen_loss_total / num_batches,\n",
    "        adv_loss_total / num_batches,\n",
    "        l1_loss_total / num_batches,\n",
    "        perc_loss_total / num_batches if include_perceptual else 0.0,\n",
    "        disc_loss_total / num_batches\n",
    "    ])\n",
    "\n",
    "    # Print loss summary\n",
    "    if include_perceptual:\n",
    "        print(f\"Epoch {epoch}/{EPOCHS} | Gen: {gen_loss_total / num_batches:.4f} | \"\n",
    "              f\"Adv: {adv_loss_total / num_batches:.4f} | L1: {l1_loss_total / num_batches:.4f} | \"\n",
    "              f\"Perc: {perc_loss_total / num_batches:.4f} | Disc: {disc_loss_total / num_batches:.4f} \"\n",
    "              f\"| Time: {int(minutes)}m {int(seconds)}s\")\n",
    "    else:\n",
    "        print(f\"Epoch {epoch}/{EPOCHS} | Gen: {gen_loss_total / num_batches:.4f} | \"\n",
    "              f\"Adv: {adv_loss_total / num_batches:.4f} | L1: {l1_loss_total / num_batches:.4f} | \"\n",
    "              f\"Disc: {disc_loss_total / num_batches:.4f} | Time: {int(minutes)}m {int(seconds)}s\")\n",
    "\n",
    "    # Evaluate model every 10 epochs\n",
    "    if epoch % 10 == 0 and include_metrics:\n",
    "        print(\"-------------------------------------\")\n",
    "        evaluate_model(subset_loader, generator, device)\n",
    "        print(\"-------------------------------------\")\n",
    "\n",
    "        # Save models\n",
    "        torch.save(generator.state_dict(), f\"Models/generator_epoch_{epoch}.pth\")\n",
    "        torch.save(discriminator.state_dict(), f\"Models/discriminator_epoch_{epoch}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9c908d2-1139-4b6f-8f24-4ac3eddaaedc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/200 | Gen: 24.8637 | Adv: 18.4064 | L1: 0.0645 | Perc: 1.0393 | Disc: 0.0000 | Time: 0m 23s\n",
      "Epoch 152/200 | Gen: 25.1130 | Adv: 18.6827 | L1: 0.0642 | Perc: 1.0382 | Disc: 0.0289 | Time: 0m 23s\n",
      "Epoch 153/200 | Gen: 23.5009 | Adv: 17.0833 | L1: 0.0641 | Perc: 1.0370 | Disc: 0.0019 | Time: 0m 22s\n",
      "Epoch 154/200 | Gen: 23.7227 | Adv: 17.3384 | L1: 0.0637 | Perc: 1.0352 | Disc: 0.0001 | Time: 0m 24s\n",
      "Epoch 155/200 | Gen: 23.9649 | Adv: 17.6090 | L1: 0.0635 | Perc: 1.0337 | Disc: 0.0001 | Time: 0m 24s\n",
      "Epoch 156/200 | Gen: 23.9786 | Adv: 17.6078 | L1: 0.0636 | Perc: 1.0333 | Disc: 0.0001 | Time: 0m 23s\n",
      "Epoch 157/200 | Gen: 24.0169 | Adv: 17.6352 | L1: 0.0637 | Perc: 1.0327 | Disc: 0.0001 | Time: 0m 21s\n",
      "Epoch 158/200 | Gen: 24.2833 | Adv: 17.9351 | L1: 0.0634 | Perc: 1.0309 | Disc: 0.0000 | Time: 0m 21s\n",
      "Epoch 159/200 | Gen: 24.6292 | Adv: 18.3246 | L1: 0.0629 | Perc: 1.0290 | Disc: 0.0000 | Time: 0m 23s\n",
      "Epoch 160/200 | Gen: 23.0824 | Adv: 16.7648 | L1: 0.0631 | Perc: 1.0283 | Disc: 0.0225 | Time: 0m 23s\n",
      "-------------------------------------\n",
      "SSIM: 0.9616 | PSNR: 26.80 dB | MSE: 0.0024 | RMSE: 0.0471\n",
      "-------------------------------------\n",
      "Epoch 161/200 | Gen: 23.2518 | Adv: 16.9468 | L1: 0.0629 | Perc: 1.0273 | Disc: 0.0109 | Time: 0m 22s\n",
      "Epoch 162/200 | Gen: 23.7760 | Adv: 17.4524 | L1: 0.0631 | Perc: 1.0267 | Disc: 0.0003 | Time: 0m 22s\n",
      "Epoch 163/200 | Gen: 23.8474 | Adv: 17.5525 | L1: 0.0628 | Perc: 1.0253 | Disc: 0.0001 | Time: 0m 22s\n",
      "Epoch 164/200 | Gen: 22.9645 | Adv: 16.7006 | L1: 0.0625 | Perc: 1.0235 | Disc: 0.0311 | Time: 0m 25s\n",
      "Epoch 165/200 | Gen: 22.1916 | Adv: 15.9277 | L1: 0.0625 | Perc: 1.0230 | Disc: 0.0049 | Time: 0m 22s\n",
      "Epoch 166/200 | Gen: 22.5928 | Adv: 16.3357 | L1: 0.0625 | Perc: 1.0221 | Disc: 0.0005 | Time: 0m 24s\n",
      "Epoch 167/200 | Gen: 23.1364 | Adv: 16.8902 | L1: 0.0624 | Perc: 1.0209 | Disc: 0.0002 | Time: 0m 24s\n",
      "Epoch 168/200 | Gen: 23.2463 | Adv: 17.0470 | L1: 0.0619 | Perc: 1.0188 | Disc: 0.0001 | Time: 0m 24s\n",
      "Epoch 169/200 | Gen: 23.5547 | Adv: 17.3377 | L1: 0.0621 | Perc: 1.0184 | Disc: 0.0001 | Time: 0m 25s\n",
      "Epoch 170/200 | Gen: 23.7582 | Adv: 17.5207 | L1: 0.0623 | Perc: 1.0183 | Disc: 0.0001 | Time: 0m 25s\n",
      "-------------------------------------\n",
      "SSIM: 0.9620 | PSNR: 26.75 dB | MSE: 0.0024 | RMSE: 0.0473\n",
      "-------------------------------------\n",
      "Epoch 171/200 | Gen: 24.0690 | Adv: 17.8654 | L1: 0.0619 | Perc: 1.0166 | Disc: 0.0000 | Time: 0m 24s\n",
      "Epoch 172/200 | Gen: 24.4395 | Adv: 18.2904 | L1: 0.0614 | Perc: 1.0144 | Disc: 0.0000 | Time: 0m 25s\n",
      "Epoch 173/200 | Gen: 24.7565 | Adv: 18.6187 | L1: 0.0613 | Perc: 1.0133 | Disc: 0.0000 | Time: 0m 22s\n",
      "Epoch 174/200 | Gen: 25.3249 | Adv: 19.1306 | L1: 0.0618 | Perc: 1.0140 | Disc: 0.0000 | Time: 0m 23s\n",
      "Epoch 175/200 | Gen: 25.6783 | Adv: 19.5110 | L1: 0.0616 | Perc: 1.0126 | Disc: 0.0000 | Time: 0m 24s\n",
      "Epoch 176/200 | Gen: 25.4412 | Adv: 19.3151 | L1: 0.0612 | Perc: 1.0103 | Disc: 0.0328 | Time: 0m 24s\n",
      "Epoch 177/200 | Gen: 23.3892 | Adv: 17.2631 | L1: 0.0612 | Perc: 1.0096 | Disc: 0.0029 | Time: 0m 22s\n",
      "Epoch 178/200 | Gen: 23.4249 | Adv: 17.2853 | L1: 0.0613 | Perc: 1.0096 | Disc: 0.0041 | Time: 0m 22s\n",
      "Epoch 179/200 | Gen: 24.3143 | Adv: 18.2099 | L1: 0.0609 | Perc: 1.0078 | Disc: 0.0003 | Time: 0m 22s\n",
      "Epoch 180/200 | Gen: 24.4697 | Adv: 18.3829 | L1: 0.0608 | Perc: 1.0066 | Disc: 0.0001 | Time: 0m 23s\n",
      "-------------------------------------\n",
      "SSIM: 0.9638 | PSNR: 27.13 dB | MSE: 0.0022 | RMSE: 0.0454\n",
      "-------------------------------------\n",
      "Epoch 181/200 | Gen: 24.6935 | Adv: 18.6010 | L1: 0.0608 | Perc: 1.0060 | Disc: 0.0000 | Time: 0m 23s\n",
      "Epoch 182/200 | Gen: 24.6193 | Adv: 18.5460 | L1: 0.0606 | Perc: 1.0048 | Disc: 0.0000 | Time: 0m 22s\n",
      "Epoch 183/200 | Gen: 24.9296 | Adv: 18.8666 | L1: 0.0605 | Perc: 1.0038 | Disc: 0.0000 | Time: 0m 22s\n",
      "Epoch 184/200 | Gen: 25.0468 | Adv: 18.9873 | L1: 0.0605 | Perc: 1.0031 | Disc: 0.0000 | Time: 0m 24s\n",
      "Epoch 185/200 | Gen: 25.1360 | Adv: 19.0888 | L1: 0.0604 | Perc: 1.0020 | Disc: 0.0000 | Time: 0m 19s\n",
      "Epoch 186/200 | Gen: 24.1167 | Adv: 18.0855 | L1: 0.0602 | Perc: 1.0011 | Disc: 0.0241 | Time: 0m 22s\n",
      "Epoch 187/200 | Gen: 24.2362 | Adv: 18.1744 | L1: 0.0605 | Perc: 1.0012 | Disc: 0.0008 | Time: 0m 23s\n",
      "Epoch 188/200 | Gen: 24.2808 | Adv: 18.2383 | L1: 0.0603 | Perc: 0.9998 | Disc: 0.0002 | Time: 0m 23s\n",
      "Epoch 189/200 | Gen: 24.0832 | Adv: 18.0733 | L1: 0.0600 | Perc: 0.9980 | Disc: 0.0001 | Time: 0m 26s\n",
      "Epoch 190/200 | Gen: 24.3324 | Adv: 18.3444 | L1: 0.0598 | Perc: 0.9968 | Disc: 0.0001 | Time: 0m 24s\n",
      "-------------------------------------\n",
      "SSIM: 0.9646 | PSNR: 27.19 dB | MSE: 0.0022 | RMSE: 0.0451\n",
      "-------------------------------------\n",
      "Epoch 191/200 | Gen: 24.7520 | Adv: 18.7566 | L1: 0.0599 | Perc: 0.9964 | Disc: 0.0000 | Time: 0m 23s\n",
      "Epoch 192/200 | Gen: 24.7071 | Adv: 18.7074 | L1: 0.0599 | Perc: 0.9958 | Disc: 0.0000 | Time: 0m 22s\n",
      "Epoch 193/200 | Gen: 25.1054 | Adv: 19.1018 | L1: 0.0599 | Perc: 0.9951 | Disc: 0.0000 | Time: 0m 24s\n",
      "Epoch 194/200 | Gen: 25.4409 | Adv: 19.4693 | L1: 0.0596 | Perc: 0.9934 | Disc: 0.0000 | Time: 0m 23s\n",
      "Epoch 195/200 | Gen: 24.6717 | Adv: 18.7144 | L1: 0.0595 | Perc: 0.9923 | Disc: 0.0365 | Time: 0m 24s\n",
      "Epoch 196/200 | Gen: 22.4795 | Adv: 16.5240 | L1: 0.0595 | Perc: 0.9918 | Disc: 0.0111 | Time: 0m 23s\n",
      "Epoch 197/200 | Gen: 22.7488 | Adv: 16.8101 | L1: 0.0593 | Perc: 0.9906 | Disc: 0.0005 | Time: 0m 24s\n",
      "Epoch 198/200 | Gen: 22.9707 | Adv: 17.0347 | L1: 0.0593 | Perc: 0.9899 | Disc: 0.0013 | Time: 0m 27s\n",
      "Epoch 199/200 | Gen: 23.0671 | Adv: 17.1444 | L1: 0.0591 | Perc: 0.9891 | Disc: 0.0004 | Time: 0m 26s\n",
      "Epoch 200/200 | Gen: 24.2579 | Adv: 18.3471 | L1: 0.0590 | Perc: 0.9882 | Disc: 0.0001 | Time: 0m 28s\n",
      "-------------------------------------\n",
      "SSIM: 0.9666 | PSNR: 27.42 dB | MSE: 0.0021 | RMSE: 0.0439\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(151, 201):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Accumulators\n",
    "    gen_loss_total = adv_loss_total = l1_loss_total = perc_loss_total = disc_loss_total = 0\n",
    "    num_batches = len(subset_loader)\n",
    "\n",
    "    for grayscale, color in subset_loader:\n",
    "        grayscale, color = grayscale.to(device), color.to(device)\n",
    "\n",
    "        if include_perceptual:\n",
    "            gen_loss, adv_loss, l1_loss, perc_loss, disc_loss = train_step(grayscale, color, include_perceptual)\n",
    "            perc_loss_total += perc_loss.item()\n",
    "        else:\n",
    "            gen_loss, adv_loss, l1_loss, disc_loss = train_step(grayscale, color, include_perceptual)\n",
    "            perc_loss = torch.tensor(0.0)  # Placeholder if not used\n",
    "\n",
    "        # Accumulate all losses\n",
    "        gen_loss_total += gen_loss.item()\n",
    "        adv_loss_total += adv_loss.item()\n",
    "        l1_loss_total += l1_loss.item()\n",
    "        disc_loss_total += disc_loss.item()\n",
    "\n",
    "    # Epoch time\n",
    "    elapsed_time = time.time() - start_time\n",
    "    minutes, seconds = divmod(elapsed_time, 60)\n",
    "\n",
    "    # Store loss values (averaged per batch)\n",
    "    loss_history.append([\n",
    "        gen_loss_total / num_batches,\n",
    "        adv_loss_total / num_batches,\n",
    "        l1_loss_total / num_batches,\n",
    "        perc_loss_total / num_batches if include_perceptual else 0.0,\n",
    "        disc_loss_total / num_batches\n",
    "    ])\n",
    "\n",
    "    # Print loss summary\n",
    "    if include_perceptual:\n",
    "        print(f\"Epoch {epoch}/{200} | Gen: {gen_loss_total / num_batches:.4f} | \"\n",
    "              f\"Adv: {adv_loss_total / num_batches:.4f} | L1: {l1_loss_total / num_batches:.4f} | \"\n",
    "              f\"Perc: {perc_loss_total / num_batches:.4f} | Disc: {disc_loss_total / num_batches:.4f} \"\n",
    "              f\"| Time: {int(minutes)}m {int(seconds)}s\")\n",
    "    else:\n",
    "        print(f\"Epoch {epoch}/{200} | Gen: {gen_loss_total / num_batches:.4f} | \"\n",
    "              f\"Adv: {adv_loss_total / num_batches:.4f} | L1: {l1_loss_total / num_batches:.4f} | \"\n",
    "              f\"Disc: {disc_loss_total / num_batches:.4f} | Time: {int(minutes)}m {int(seconds)}s\")\n",
    "\n",
    "    # Evaluate model every 10 epochs\n",
    "    if epoch % 10 == 0 and include_metrics:\n",
    "        print(\"-------------------------------------\")\n",
    "        evaluate_model(subset_loader, generator, device)\n",
    "        print(\"-------------------------------------\")\n",
    "\n",
    "        # Save models\n",
    "        torch.save(generator.state_dict(), f\"Models/generator_epoch_{epoch}.pth\")\n",
    "        torch.save(discriminator.state_dict(), f\"Models/discriminator_epoch_{epoch}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5121366-080a-4e9f-be87-d78418ddb1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert to numpy array and save\n",
    "np.save(\"Pizx2pix_Percpetual_loss_history.npy\", np.array(loss_history))\n",
    "\n",
    "# Load it later:\n",
    "# loss_history = np.load(\"loss_history.npy\", allow_pickle=True).tolist()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
